theory SubsetSum_PneqNP
  imports SubsetSum_CookLevin
begin

text â€¹

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                            %
%                A CONDITIONAL PROOF THAT  P â‰  NP  FROM A                    %
%           STRUCTURAL LRâ€“READ ASSUMPTION ON SUBSETâ€“SUM SOLVERS              %
%                                                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This chapter presents the conceptual, mathematical, and philosophical
background to the formalisation developed in this theory. The central goal
is to explainâ€”in clear, non-technical languageâ€”the structure of the
argument, which portions are fully formalised in Isabelle/HOL, and which
portion is assumed as an axiom due to deep complexity-theoretic reasons.

The technical machinery of this chapter realises, in verified form,
a conditional statement of the following kind:

     *If every polynomial-time Turing machine that solves SUBSET-SUM
      satisfies a certain natural information-use property
      (the LRâ€“read property), then P â‰  NP.*

The information-use property in question has an intuitive
computational meaning:

     **When a machine decides whether two quantities L and R are equal,
       it must look at at least one bit of the part of the input that
       encodes L, and at least one bit of the part that encodes R.**

The argument originates from a 2016 paper of Craig A. Feinstein:

   â€¢ C. A. Feinstein,  
     â€œDialogue Concerning the Two Chief World Views,â€  
     arXiv:1605.08639.

This Isabelle/HOL development extracts and formalises the *lower-bound
core* of that paper in a precise, modular, and fully verified way.

Along the way, the author received assistance from two AI systemsâ€”
**ChatGPT** (OpenAI) and **Claude AI** (Anthropic)â€”primarily in generating
explanatory text, improving accessibility, and refining the presentation
of structural assumptions.  All proofs included in this repository are
fully verified by Isabelle/HOL.

Before describing the results, we begin with the computational
intuitions.

-------------------------------------------------------------------------------
1.  Why SUBSET-SUM?
-------------------------------------------------------------------------------

Among NP-complete problems, SUBSET-SUM has a particularly simple
combinatorial structure: for a list of integers `as = [aâ‚€, aâ‚, ..., aâ‚™â‚‹â‚]`
and target `s`, the question is whether one can choose a 0/1 vector `xs`
such that

          aâ‚€Â·xsâ‚€  +  â‹¯  +  aâ‚™â‚‹â‚Â·xsâ‚™â‚‹â‚  =  s.

The key combinatorial fact is that, for certain carefully chosen lists
(as constructed in SubsetSum_DecisionTree), *all* 2â¿ possible subset
sums are distinct. These are the **hard instances**: no two subsets have
the same sum.

On such instances, deciding whether a particular sum equals s requires a
nontrivial amount of information about xs. This observation forms the
foundation for the adversary argument.

-------------------------------------------------------------------------------
2.  The Decision-Tree Lower Bound (recap)
-------------------------------------------------------------------------------

The theory SubsetSum_DecisionTree defines an abstract reader model for
SUBSET-SUM and proves the lower bound

      steps as s â‰¥ 2 * âˆš(2^n)

on the hard family of length-n instances with distinct subset sums.

Informally, the model views a computation as an adversary game:

  â€¢ The algorithm reads bits of the *real* input (as, s).  
  â€¢ An adversary maintains â€œvirtual completionsâ€ xs âˆˆ {0,1}â¿ that are
    consistent with everything the algorithm has seen so far.  
  â€¢ For each split k, the canonical equation eâ‚–(as, s) has a left-hand
    side L(xs) depending on the first k bits and a right-hand side R(xs)
    depending on the remaining n âˆ’ k bits.

As xs varies, the possible L- and R-values form sets LHS(eâ‚–) and RHS(eâ‚–)
of sizes 2áµ and 2â¿â»áµ.  The algorithm never reads xs directly; these sets
are a way of tracking how many â€œvirtual worldsâ€ remain indistinguishable
given what has been read from (as, s).  The abstract axioms state that

  â€¢ for some split k, the algorithmâ€™s information flow aligns with the
    canonical LHS/RHS decomposition; and  

  â€¢ each distinct L- or R-value that must be distinguished costs at
    least one unit of work.

On the hard family with distinct subset sums this yields

      steps as s â‰¥ 2áµ + 2â¿â»áµ

for some k â‰¤ n, and minimising this expression over k gives

      steps as s â‰¥ 2 * âˆš(2^n).

All of this is proved once and for all in SubsetSum_DecisionTree and
exposed via the locale SubsetSum_Lemma1. The present theory does not
reprove the lower bound; it only transports it to Turing machines under
the LRâ€“read assumption.

-------------------------------------------------------------------------------
3.  From Decision Trees to Turing Machines
-------------------------------------------------------------------------------

A Cookâ€“Levin Turing machine is more flexible than a decision tree:
  â€¢ it may encode the input arbitrarily,  
  â€¢ it may read bits in any order,  
  â€¢ it may interleave, compress, or duplicate portions of the encoding.

Thus, even though we have *proven* that any decision-tree needs at least
2âˆš(2â¿) reads, this does not automatically imply the same statement for
Turing machines.

The bridge between these models is encapsulated in the locale
LR_Read_TM, which formalises a simple requirement:

    **A solver for SUBSET-SUM must actually read information from both
       the region encoding the left side of the deciding equation
       and from the region encoding the right side.**

Inside LR_Read_TM, this requirement is expressed via abstract â€œseenâ€
sets that satisfy the axioms of SubsetSum_Lemma1, so the âˆš(2â¿) lower
bound carries over to the Cookâ€“Levin step-count of any solver satisfying
LRâ€“read.

-------------------------------------------------------------------------------
4.  Why LRâ€“Read is Assumed, Not Proven
-------------------------------------------------------------------------------

The locale P_neq_NP_LR_Model includes, as an explicit assumption, that
every polynomial-time SUBSET-SUM solver satisfies the LRâ€“read property:
when processing instances with distinct subset sums, the solver must
extract some information about the â€œleftâ€™â€™ part and some information
about the â€œrightâ€™â€™ part of the deciding equation.

This principle is **not proved** in this development â€” it is *axiomatised*.
The reason is straightforward:

    **If one could prove that every P-time SUBSET-SUM solver must
       satisfy LRâ€“read, then one would immediately obtain P â‰  NP.**

Within the locale LR_Read_TM, the LRâ€“read property implies a
Î©(âˆš(2â¿)) lower bound on the distinct-subset-sums family.  A *universal*
LRâ€“read theorem would therefore rule out the existence of any
polynomial-time algorithm for SUBSET-SUM, and since SUBSET-SUM is
NP-complete, this would yield P â‰  NP.  Proving such a universal property
is thus expected to be at least as hard as resolving P vs NP itself.

There is also a conceptual justification following ideas of Gregory Chaitin,
who argues that mathematics is inherently incomplete and that certain deep
computational principles may not be derivable within existing axiomatic
systems without introducing new axioms.  See:

      G. J. Chaitin, "Thoughts on the Riemann Hypothesis,"
      arXiv:math/0306042 (2003).

The LRâ€“read principle fits naturally into this viewpoint. It expresses a
fundamental information-flow constraint: to determine whether L = R, one
must obtain information about both L and R.  While this seems intuitively
necessary, proving it holds universally for all polynomial-time algorithms
would require techniques beyond those currently available.  Treating it
as an explicit axiom therefore clarifies the logical structure of the
argument rather than weakening it.

Everything else in this development â€” the âˆš(2â¿) lower bound, the
decision-tree instantiation, and the Cookâ€“Levin bridge â€” is fully
verified in Isabelle/HOL.  The **only** non-proven component is the
universal validity of LRâ€“read, which is intentionally left as a clear
and explicit assumption.  This axiom is falsifiable: exhibiting a
polynomial-time SUBSET-SUM solver that demonstrably violates LRâ€“read
would refute it, while leaving the verified lower-bound kernel intact.

-------------------------------------------------------------------------------
5.  The Logical Structure of the Isabelle Development
-------------------------------------------------------------------------------

The Isabelle formalisation splits cleanly into three layers:

(1) **Formal lower-bound kernel (fully proven)**  
    From SubsetSum_DecisionTree and abstract reader assumptions,  
    we prove:

         steps â‰¥ 2âˆš(2^n)

    on the hard family of instances with distinct subset sums.

(2) **Cookâ€“Levin bridge (fully formal on the TM side)**  
    We encode SUBSET-SUM as a Cookâ€“Levin Turing machine input,  
    show that SUBSETSUM_lang enc0 lies in ğ’©ğ’«, and define LR_Read_TM
    as the Turing-machine analogue of the abstract reader model.

(3) **One explicit modelling assumption (axiom)**  
    If SUBSET-SUM âˆˆ P, then there exists a polynomial-time solver whose
    behaviour satisfies the LRâ€“read property.

This is the only place where we assume anything not formally justified.
Everything else is mechanised.

Under these assumptions, we obtain the main conditional statement:

      **If SUBSET-SUM lies in P and every such solver satisfies LRâ€“read,
        then P â‰  NP.**

Equivalently, relative to the modelling assumptions packaged in
the locale P_neq_NP_LR_Model:

      **If every polynomial-time SUBSET-SUM solver can be represented
         as an equation-based solver and every such solver satisfies
         the LRâ€“read property, then P â‰  NP.**

-------------------------------------------------------------------------------
6.  Relationship to Feinstein (2016)
-------------------------------------------------------------------------------

Feinsteinâ€™s original paper proposed an informal argument that SUBSET-SUM
requires exponential time because verifying equality of the â€œleftâ€ and
â€œrightâ€ sums requires inspecting many possible configurations.

This Isabelle development isolates the *exact* combinatorial content
of that argument, formalises it rigorously in the decision-tree model,
and identifies the **one** structural assumption needed to transfer the
argument to Turing machines.

The result is a more precise, modular, and verifiable form of the
original intuition.

-------------------------------------------------------------------------------
7.  Philosophical Perspective and Natural Proofs
-------------------------------------------------------------------------------

This work can be viewed as an example of Chaitinâ€™s thesis that certain
deep computational truths may require additional axioms beyond those
typically considered in mathematics.

The LRâ€“read assumption expresses a fundamental asymmetry between
information and ignorance:

    â€œOne cannot determine the relationship between two quantities
     without extracting information about each one.â€

This is arguably more a law of computation than a theorem, and our
formalisation shows how such a principle can be cleanly integrated into
a rigorous mathematical framework.

This formalisation is not intended as a proof of P â‰  NP.  Rather, it
provides a fully verified framework in which the classical adversary
lower bound for SUBSET-SUM can be transported to the Cookâ€“Levin model,
conditional on a single, clearly stated structural assumption: the
LRâ€“read property.

In light of the Natural Proofs barrier (Razborovâ€“Rudich, 1997), a
universal information-use principle of this form is widely believed
to be unprovable in ZFC by currently known â€œnaturalâ€™â€™ techniques,
without conflicting with standard cryptographic assumptions.  Accordingly,
the formalisation should be viewed as a case study in identifying the
precise informational axiom required for this style of adversary
argument, rather than as progress toward resolving P vs NP.

The lower-bound kernel itself is fully mechanised and may prove reusable
in future developments.

-------------------------------------------------------------------------------
8.  The Final Conditional Theorem
-------------------------------------------------------------------------------

The main theorem of SubsetSum_PneqNP is:

    **Assuming that every polynomial-time SUBSET-SUM solver satisfies LRâ€“read,
      we have P â‰  NP.**

This shows that a very simple, very natural informational principle
â€”one likely unprovable for deep reasonsâ€”bridges the gap between the
formal combinatorial lower-bound core and a full separation of
complexity classes.

The contribution of this AFP entry is therefore twofold:

  â€¢ a fully formalised lower-bound engine for SUBSET-SUM (independent
    of unproven assumptions), and

  â€¢ a transparent, honest top-level axiom that pinpoints exactly which
    structural fact is needed to conclude P â‰  NP.

This approach does not claim to *prove* P â‰  NP outright, but it provides
a powerful blueprint:

**identify the minimal structural axiom needed, formalise everything
around it, and expose precisely what remains to be shown.**
â€º

definition P_eq_NP :: bool where
  "P_eq_NP âŸ· (âˆ€L::language. (L âˆˆ ğ’«) = (L âˆˆ ğ’©ğ’«))"

text â€¹
  --------------------------------------------------------------------------
  â–  Summary of the LRâ€“read meta-assumptions
  --------------------------------------------------------------------------

  The locale P_neq_NP_LR_Model collects the three global assumptions
  needed to transport the LRâ€“read lower bound (proved in the locale
  LR_Read_TM) into a full conditional â€œP â‰  NPâ€ result.

  These assumptions are not lower-bound lemmas themselves; they are
  *meta-level statements* about how polynomial-time Cookâ€“Levin machines
  behave when solving SUBSET-SUM.  They provide the bridge from

        â€œSUBSET-SUM âˆˆ Pâ€

  to

        â€œsome solver must satisfy LRâ€“readâ€.

  (1) **NP membership.**  
      For the chosen encoding enc0, the SUBSET-SUM language satisfies  
         SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«.  
      This is fully formalised using NP verifiers.

  (2) **P â‡’ equation-based solver.**  
      If SUBSETSUM_lang enc0 lies in ğ’«, then there exists a
      polynomial-time Cookâ€“Levin machine whose correctness is expressed
      via an equality of two abstract sides

         lhs as s = rhs as s

      and whose reading behaviour satisfies the locale
      Eq_ReadLR_SubsetSum_Solver.

  (3) **Equation-based â‡’ LRâ€“read.**  
      Any such equation-based, polynomial-time solver must in fact satisfy
      the structured LR-read interface

         LR_Read_TM M q0 enc seenL seenR.

      This is the Cookâ€“Levin analogue of the abstract reader model from
      the decision-tree theory.

  Together, these assumptions provide exactly what is needed to lift the
  âˆš(2â¿) lower bound from abstract reader models to Cookâ€“Levin machines,
  and ultimately to derive the conditional theorem that *if every P-time
  SUBSET-SUM solver satisfies LRâ€“read, then P â‰  NP*.

  --------------------------------------------------------------------------
  â–  Why the locale P_neq_NP_LR_Model is needed
  --------------------------------------------------------------------------

  Up to this point, the development has proved two kinds of results:

    â€¢ *Fully formal combinatorial lower bounds*  
      (SubsetSum_DecisionTree, SubsetSum_Lemma1, LR_Read_TM),
      showing that any solver satisfying LRâ€“read must take at least âˆš(2â¿)
      steps on the distinct-subset-sums family.

    â€¢ *Concrete Cookâ€“Levin encodings*,  
      showing SUBSET-SUM âˆˆ NP and formalising the notion of an
      equation-based solver (Eq_ReadLR_SubsetSum_Solver).

  What has **not** been proved â€” and what modern complexity theory strongly
  suggests cannot be proved â€” is the missing implication:

      Every polynomial-time Cookâ€“Levin solver for SUBSET-SUM
         â‡’ satisfies LR_Read_TM.

  Such a statement would assert a universal structural constraint on 
  the behaviour of all polynomial-time algorithms for SUBSET-SUM. 
  Complexity theory provides several indications â€” most prominently 
  the Razborovâ€“Rudich Natural Proofs framework â€” that broad, efficiently 
  checkable invariants of all P-time algorithms are difficult to prove 
  using current techniques, especially when they interact with standard 
  cryptographic assumptions such as pseudorandom functions.

  Our development does not rely on Natural Proofs in any technical sense, 
  and the LRâ€“read lower bound itself is not a natural proof. The connection 
  is only heuristic: it suggests that proving a universal information-use 
  property of all polynomial-time solvers may be beyond presently known 
  methods, which motivates treating LRâ€“read as an explicit modelling 
  assumption rather than a derived theorem.

  Therefore the unprovable step is isolated as an explicit, clean
  modelling assumption.  The locale P_neq_NP_LR_Model packages the
  following three assumptions:

    (1) SUBSET-SUM âˆˆ NP for the fixed encoding enc0.  
        (Fully formalised.)

    (2) If SUBSET-SUM âˆˆ P, then there exists an equation-based
        polynomial-time solver (Eq_ReadLR_SubsetSum_Solver).  
        (Modelling assumption: p-time solvers can be expressed semantically
         as L = R.)

    (3) Every such solver satisfies LR-read (LR_Read_TM) for some
        seenL, seenR.  
        (Crucial structural assumption: allows importing the âˆš(2â¿) bound.)

  With these assumptions, the lower bounds proved in LR_Read_TM
  immediately imply that **no polynomial-time Cookâ€“Levin solver can
  exist** on the distinct-subset-sums family.  Since

        P = NP â‡’ SUBSET-SUM âˆˆ P,

  this yields the conditional theorem:

      **If every P-time SUBSET-SUM solver satisfies LRâ€“read,
         then P â‰  NP.**

  --------------------------------------------------------------------------
  â–  Why the locale theorem expresses exactly:
        â€œIf every polynomial-time solver has LRâ€“read, then P â‰  NP.â€
  --------------------------------------------------------------------------

  The intended high-level implication is:

        (âˆ€ polynomial-time SUBSET-SUM solvers M.  M satisfies LRâ€“read)
           âŸ¹   P â‰  NP.

  In Isabelle this is decomposed using locales:

    â€¢ LR_Read_TM  
      formalises the LR-read property and imports the âˆš(2â¿) lower bound.
      Any solver inside this locale cannot be polynomial-time.

    â€¢ Eq_ReadLR_SubsetSum_Solver  
      describes solvers that operate via an L/R equality.  Assumption (A3)
      of P_neq_NP_LR_Model states that **every** such polynomial-time
      solver satisfies LR-read.  Hence every such solver inherits the
      âˆš(2â¿) lower bound.

    â€¢ P_neq_NP_LR_Model  
      collects the three meta-assumptions (A1)â€“(A3):

         (A1) SUBSET-SUM âˆˆ NP,  
         (A2) If SUBSET-SUM âˆˆ P, then an equation-based p-time solver exists,  
         (A3) Every such solver satisfies LR-read (hence cannot be p-time).

      Under P = NP, (A1) and (A2) give a p-time solver, while (A3) forbids
      one.  Contradiction.

  Thus the locale theorem P_neq_NP_from_LR exactly formalises the
  conditional statement:

      **If every polynomial-time SUBSET-SUM solver has the LRâ€“read property,
         then P â‰  NP.**
â€º

locale P_neq_NP_LR_Model =
  fixes enc0     :: "int list â‡’ int â‡’ string"
    and k        :: nat              (* number of tapes for the NP TM *)
    and q0V      :: nat              (* start state for the NP verifier V *)
    and V        :: machine          (* NP-style Turing machine *)
    and p        :: "nat â‡’ nat"
    and T        :: "nat â‡’ nat"
    and fverify  :: "string â‡’ string"
    and enc_cert :: "int list â‡’ int â‡’ int list â‡’ string"
  assumes SS_verifier:
    "SS_Verifier_NP k q0V V p T fverify enc0 enc_cert"
  assumes P_impl_eq_readlr_CL_global:
    "SUBSETSUM_lang enc0 âˆˆ ğ’« âŸ¹
       âˆƒM q0 enc lhs rhs L_zone R_zone.
         Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone âˆ§
         polytime_CL_machine M enc"
  assumes eq_to_LR_Read_TM_global:
    "â‹€M q0 enc lhs rhs L_zone R_zone.
       Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone âŸ¹
       polytime_CL_machine M enc âŸ¹
       (âˆƒseenL seenR. LR_Read_TM M q0 enc seenL seenR)"
begin

lemma SUBSETSUM_in_NP_global:
  "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  using SUBSETSUM_in_NP_from_verifier[OF SS_verifier] .

lemma no_polytime_eq_readlr_solver:
  shows "Â¬ (âˆƒM q0 enc lhs rhs L_zone R_zone.
              Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone âˆ§
              polytime_CL_machine M enc)"
proof
  assume ex:
    "âˆƒM q0 enc lhs rhs L_zone R_zone.
       Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone âˆ§
       polytime_CL_machine M enc"
  then obtain M q0 enc lhs rhs L_zone R_zone where
    solver: "Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone" and
    poly:   "polytime_CL_machine M enc"
    by blast

  text â€¹Use the bridge: any such equation-based solver gives an LR_Read_TM.â€º
  from eq_to_LR_Read_TM_global[OF solver poly]
  obtain seenL seenR where lr: "LR_Read_TM M q0 enc seenL seenR"
    by blast

  interpret LR: LR_Read_TM M q0 enc seenL seenR
    by (rule lr)

  text â€¹From polynomial-time on all inputs we deduce an (assumed)
    polynomial bound on the distinct-subset-sums family.â€º

  from poly obtain c d where
    cpos: "c > 0" and
    bound_all: "âˆ€as s. steps_CL M (enc as s)
                       â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
    unfolding polytime_CL_machine_def by blast

  have family_bound:
    "âˆƒ(c::real)>0. âˆƒd::nat.
       âˆ€as s. distinct_subset_sums as âŸ¶
         steps_CL M (enc as s)
           â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
    using cpos bound_all by blast

  text â€¹But LR_Read_TMâ€™s inherited lower bound says no such polynomial
    bound exists on the distinct-subset-sums family.â€º
  from LR.no_polytime_CL_on_distinct_family family_bound
  show False by blast
qed

theorem P_neq_NP_from_LR:
  "Â¬ P_eq_NP"
proof
  assume eq: P_eq_NP

  have eq_PNP_inst:
    "(SUBSETSUM_lang enc0 âˆˆ ğ’«) = (SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«)"
    using eq unfolding P_eq_NP_def by simp

  have inP_SUBSETSUM: "SUBSETSUM_lang enc0 âˆˆ ğ’«"
  proof -
    have "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
      by (rule SUBSETSUM_in_NP_global)
    thus ?thesis
      using eq_PNP_inst by simp
  qed

  text â€¹By the modelling assumption, this yields an equation-based,
    polynomial-time Cookâ€“Levin solver for SUBSET-SUM.â€º
  from P_impl_eq_readlr_CL_global[OF inP_SUBSETSUM]
  obtain M q0 enc lhs rhs L_zone R_zone where
    solver: "Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone" and
    poly:   "polytime_CL_machine M enc"
    by blast

  text â€¹Package this solver as a witness for the existential that
    no_polytime_eq_readlr_solver forbids.â€º
  have ex_solver:
    "âˆƒM q0 enc lhs rhs L_zone R_zone.
       Eq_ReadLR_SubsetSum_Solver M q0 enc lhs rhs L_zone R_zone âˆ§
       polytime_CL_machine M enc"
    using solver poly by blast

  from no_polytime_eq_readlr_solver ex_solver
  show False by blast
qed

end  (* context P_neq_NP_LR_Model *)

text â€¹Non-locale exported version:

  If some encoding enc0 and assumptions
  P_neq_NP_LR_Model enc0 hold, then P â‰  NP.
â€º

theorem P_neq_NP_from_LR_global:
  assumes "P_neq_NP_LR_Model enc0 k G V p T fverify enc_cert"
  shows "Â¬ P_eq_NP"
proof -
  interpret P_neq_NP_LR_Model enc0 k G V p T fverify enc_cert by fact
  from P_neq_NP_from_LR show ?thesis .
qed

end  (* theory *)
