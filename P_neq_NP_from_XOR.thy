theory SubsetSum_PneqNP
  imports SubsetSum_CookLevin
begin

text â€¹
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%      A CONDITIONAL PROOF THAT P â‰  NP FROM AN INFORMATION-FLOW PRINCIPLE     %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This theory completes a mechanised formalisation of the lower-bound argument for
SUBSETâ€“SUM originating in

    C. A. Feinstein,
    â€œDialogue Concerning the Two Chief World Views,â€
    arXiv:1605.08639.

The development begins from a simple and intuitively compelling information-flow
principle:

      To decide whether two quantities L and R are equal,
      a solver must obtain some information about L
      and some information about R.

In the SUBSETâ€“SUM setting, this principle takes on a precise combinatorial form.
For each split position k, the canonical decomposition eâ‚–(as, s) rewrites the
verification equation into two independent collections of candidate contributions:

      LHS(eâ‚– as s)     of size 2^k,
      RHS(eâ‚– as s)     of size 2^(n âˆ’ k),

arising respectively from all prefix-choices and all suffix-choices of the
unknown selection vector xs.  Determining whether a solution exists is
equivalent to determining whether these two sets intersect.

A crucial observation is that **each** element of LHS(eâ‚–) and **each** element of
RHS(eâ‚–) corresponds to a different feasible completion of xs.  Before the solver
has read the input, all such completions are consistent with the instance; none
may be discarded a priori.  Therefore, in the worst case, a correct solver must
acquire enough information to distinguish *every* canonical L-value and *every*
canonical R-value.  Otherwise, it cannot rule out the possibility that an
unexamined L equals an unexamined R.

This explains why the informal information principle forces the solver to
distinguish all canonical candidates: every undistinguished candidate is a live
possibility, and eliminating all possibilities except the true one requires
distinguishing them one by one.

When this informational requirement is expressed inside the Cookâ€“Levin
Turing-machine framework, it becomes the LR-read property: a structural
assumption asserting that, for some split k, the machineâ€™s observable behaviour
distinguishes exactly the canonical left and right candidate sets LHS(eâ‚–) and
RHS(eâ‚–).  LR-read is the single assumption needed to transfer the abstract
decision-tree lower bound to the Turing-machine model.

Under LR-read, the formalisation proves that any solver must take at least

      2 Â· sqrt(2^n)

steps on distinct-subset-sum inputs of length n.  Since this quantity grows
faster than any polynomial, we obtain the conditional implication:

      If every polynomial-time solver for SUBSETâ€“SUM satisfies LR-read,
      then P â‰  NP.

All mathematical components except LR-read itself are fully mechanised in
Isabelle/HOL: the decision-tree adversary argument, the Cookâ€“Levin machine
semantics (from the AFPâ€™s Cookâ€“Levin library), and the NP verifier for
SUBSETâ€“SUM.  LR-read is the single explicit information-flow hypothesis that
links these components.

AI systems (ChatGPT and Claude) assisted in improving the exposition and
organisation of the informal text; all formal proofs are verified by Isabelle/HOL.
â€º


section â€¹1.  Why SUBSETâ€“SUM?â€º

text â€¹
Our interest in SUBSETâ€“SUM begins with a basic information principle:

      To decide whether two quantities L and R are equal,
      a solver must obtain some information about L
      and some information about R.

In SUBSETâ€“SUM, each 0/1-choice vector xs determines the value

      âˆ‘áµ¢ as!i * xs!i,

and for distinct-subset-sum instances these values are all different.
Thus each xs represents a *distinct candidate contribution* to the equation.

Splitting the sum at a position k separates these contributions into two
canonical candidate families:

      LHS(eâ‚– as s)    determined by xs[0..kâˆ’1],
      RHS(eâ‚– as s)    determined by xs[k..nâˆ’1].

If we treat the elements of LHS(eâ‚–) and RHS(eâ‚–) as *independent candidates*,
then solvability at split k is equivalent to asking whether these two sets
intersect.  Crucially, for distinct-subset-sum instances, **each element in each
set corresponds to a different feasible choice of xs**, and the solver has no
prior information about which choices are viable.

Therefore, to determine whether any intersection exists, the solver must be able
to distinguish all relevant candidates on both sides.  This informational
perspectiveâ€”the idea that the solver must gather enough data to rule out or
confirm each independent candidate L- and R-valueâ€”is what ultimately drives the
lower-bound argument in the remainder of the theory.
â€º


section â€¹2.  The Decision-Tree Lower Boundâ€º

text â€¹
  We briefly recall the abstract lower bound developed in the theory
  â€¹SubsetSum_DecisionTreeâ€º; see that file for full details and proofs.

  In the reader model, a solver gradually acquires information about the
  unknown choice vector xs, while an adversary tracks all choices still
  compatible with the solverâ€™s observations.  For each split position k, the
  canonical decomposition eâ‚–(as, s) induces two families of candidate
  contributions

      LHS(eâ‚– as s)    and    RHS(eâ‚– as s),

  arising respectively from all prefix-choices and all suffix-choices of xs.

  Two abstract axioms are imposed on this model:

    â€¢ â€¹coverageâ€º â€” on each distinct-subset-sum instance there exists a split
      k such that the solverâ€™s â€œseenâ€ sets coincide with the canonical
      families LHS(eâ‚– as s) and RHS(eâ‚– as s);

    â€¢ â€¹costâ€º â€” the solver must spend at least one unit of work for every
      candidate value it distinguishes on either side.

  From these assumptions alone, the locale â€¹SubsetSum_Lemma1â€º proves that at
  the relevant split k we have

      steps(as, s)  â‰¥  2^k + 2^(n âˆ’ k),

  and therefore, after minimising over k,

      steps(as, s)  â‰¥  2 Â· sqrt(2^n).

  No mention of Turing machines or encodings is needed at this stage; the
  argument is entirely combinatorial.  The remainder of the present theory
  explains how this abstract lower bound is transported into the Cookâ€“Levin
  machine model.
â€º


section â€¹3.  From Decision Trees to Cookâ€“Levin Turing Machinesâ€º

text â€¹
The abstract âˆš(2^n) lower bound from Section 2 applies to a reader model that
directly exposes which canonical candidate values LHS(eâ‚– as s) and RHS(eâ‚– as s)
the solver has distinguished.  A Cookâ€“Levin Turing machine, however, is much
more flexible: it may reorder, copy, compress, or hash its input, and none of
this internal bookkeeping corresponds directly to the abstract â€œseenâ€ sets of
the reader model.

To transport the abstract lower bound into the Cookâ€“Levin setting, the theory
â€¹SubsetSum_CookLevinâ€º introduces the locale â€¹LR_Read_TMâ€º.  It provides a way to
*interpret* a Turing machineâ€™s observable behaviour in terms of two effective
distinguishability sets

      seenL_TM as s k    and    seenR_TM as s k,

which play the role of the abstract seenL/seenR of â€¹SubsetSum_Lemma1â€º.
Roughly speaking, these sets measure what the machine has effectively learned
about prefix-determined and suffix-determined contributions at split position k.

The LR-read assumptions assert that, for each distinct-subset-sum instance,
there exists a split k such that

      seenL_TM as s k = LHS(eâ‚– as s)
      seenR_TM as s k = RHS(eâ‚– as s),

and that distinguishing each candidate value costs at least one step:

      steps_TM as s â‰¥ |seenL_TM as s k| + |seenR_TM as s k|.

With these two statements in place, the abstract reader lemma applies
verbatim with steps = steps_TM and seenL/seenR = seenL_TM/seenR_TM, yielding
for Turing machines exactly the same lower bound as in the reader model:

      steps_TM as s â‰¥ 2 Â· sqrt(2^n).

Thus the role of â€¹LR_Read_TMâ€º is purely structural: it aligns the observable
behaviour of a Cookâ€“Levin machine with the information pattern that drives the
decision-tree lower bound.  Once this alignment is postulated, the transfer of
the âˆš(2^n) bound is immediate.
â€º


section â€¹4.  Why LR-read is Assumedâ€º

text â€¹
Unlike in the decision-tree model, LR-read cannot be derived from general
adversary arguments in the unrestricted Turing-machine setting.  The reason is
fundamental: a Turing machine begins its computation with the *entire* input
visible on its tape and is free to reorganise it internally in arbitrary ways.
An adversary has no control over how the machine structures or processes this
information once the computation starts.

A helpful analogy is the following.  In a hidden-information card game, a player
learns one card at a time while the opponent keeps the remaining cards concealed;
adversary arguments succeed precisely because the opponent controls which cards
remain hidden.  In contrast, a Turing machine begins with all cards face up.  It
may sort, copy, compress, and combine these cards internally, and an adversary
cannot force it to derive information according to any particular pattern â€” in
particular, not according to the canonical L/R split underlying SUBSETâ€“SUM.

For this reason, LR-read is introduced explicitly as a *modelling assumption*
capturing a specific information-flow discipline: at some split k, the machine's
behaviour must distinguish exactly the canonical candidate sets LHS(eâ‚–) and
RHS(eâ‚–).  This assumption is the bridge that allows the abstract lower bound to
apply to Turing machines; it is not expected to follow from generic adversarial
reasoning.
â€º


section â€¹5.  Logical Structureâ€º

text â€¹
The development is organised in three layers:

  (1) Lower-bound kernel â€” *proved*
      Theories â€¹SubsetSum_DecisionTreeâ€º and â€¹SubsetSum_Lemma1â€º prove a
      âˆš(2^n) lower bound under abstract L/R-information axioms.

  (2) Cookâ€“Levin bridge â€” *proved*
      The locale â€¹LR_Read_TMâ€º formalises how a Turing machine induces the
      distinguishability sets â€¹seenL_TMâ€º and â€¹seenR_TMâ€º required by the
      abstract lemma.

  (3) Modeling assumption â€” not proved
      Every Cookâ€“Levin Turing-machine solver for SUBSETâ€“SUM (with encoding enc0)
      satisfies LR-read.

Together these yield the conditional implication:

      If SUBSETâ€“SUM âˆˆ P and all solvers satisfy LR-read,
      then P â‰  NP.
â€º


section â€¹6.  Relation to Feinstein (2016)â€º

text â€¹
Feinsteinâ€™s 2016 paper emphasises an informational viewpoint: verifying a
candidate equality requires analysing contributions coming from two independent
parts of a decomposed expression.  For SUBSETâ€“SUM, the canonical split eâ‚–(as, s)
exhibits exactly such a decomposition into prefix-determined and
suffix-determined contributions.

This formalisation captures that insight in two layers:

  â€¢ In the abstract reader model, the families LHS(eâ‚– as s) and RHS(eâ‚– as s)
    are treated as independent candidate sets.  The axioms of
    â€¹SubsetSum_Lemma1â€º express the requirement that a solver must distinguish
    all candidates on both sides, yielding the âˆš(2^n) lower bound.

  â€¢ In the Turing-machine model, the locale â€¹LR_Read_TMâ€º provides the structural
    assumption that the machineâ€™s observable behaviour distinguishes exactly
    these same canonical families at some split k.  Once LR-read is assumed,
    the abstract lower bound transfers directly to Turing machines.

Thus the formal development isolates the combinatorial kernel of Feinsteinâ€™s
argument while making explicit the single structural hypothesis (LR-read)
required to connect it to Turing-machine computation.
â€º


section â€¹7.  Perspectiveâ€º

text â€¹
The development provides a conditional lower-bound framework for SUBSETâ€“SUM
within the Cookâ€“Levin Turing-machine model.  All mathematically substantial
components â€” the decision-tree adversary argument, the Cookâ€“Levin operational
semantics, and NP-membership via an explicit verifier â€” are fully formalised in
Isabelle/HOL.

The only non-mechanised ingredient is the LR-read assumption.  It encapsulates a
specific information-flow principle: any solver must obtain enough information
about both the prefix-determined and suffix-determined candidate contributions
to determine whether a solution exists.  When LR-read is postulated for all
polynomial-time solvers, the âˆš(2^n) lower bound contradicts any polynomial
upper bound, yielding the conditional implication:

      If every polynomial-time solver for SUBSETâ€“SUM satisfies LR-read,
      then P â‰  NP.

In this way, the formalisation separates the purely combinatorial content of the
lower bound from the modelling assumption under which it applies to Turing
machines.
â€º


section â€¹8.  SUBSETâ€“SUM is in NP (formalised)â€º

text â€¹
  The technical work showing that SUBSETâ€“SUM belongs to â€¹ğ’©ğ’«â€º has already been
  carried out in â€¹SubsetSum_CookLevinâ€º.  There we introduced the locale
  â€¹SS_Verifier_NPâ€º, which packages an arbitrary NP-style verifier for
  SUBSETâ€“SUM (instance and certificate encodings, a polynomial-time verifier
  machine, and soundness/completeness assumptions), and proved the lemma

      SUBSETSUM_in_NP_from_verifier :
        SS_Verifier_NP k G V p T fverify enc0 enc_cert
        âŸ¹ SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«.

  In the present theory we simply reuse that result under a slightly more
  convenient name:
â€º

lemma SUBSETSUM_in_NP_global:
  assumes "SS_Verifier_NP k G V p T fverify enc0 enc_cert"
  shows "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  using SUBSETSUM_in_NP_from_verifier[OF assms] .

section â€¹9.  Definition of P = NPâ€º

definition P_eq_NP :: bool where
  "P_eq_NP âŸ· (âˆ€L::language. (L âˆˆ ğ’«) = (L âˆˆ ğ’©ğ’«))"


section â€¹10.  Bridging P to a concrete CL solverâ€º

text â€¹
If SUBSETâ€“SUM âˆˆ P, then some Cookâ€“Levin machine solves it in polynomial time.

This step passes from language complexity to concrete machine semantics.
The solverâ€™s encoding need not match the verifierâ€™s encoding; only the language
matters.
â€º

definition P_impl_CL_SubsetSum_Solver ::
  "(int list â‡’ int â‡’ string) â‡’ bool" where
  "P_impl_CL_SubsetSum_Solver enc0 âŸ·
     (SUBSETSUM_lang enc0 âˆˆ ğ’« âŸ¶
        (âˆƒM q0 enc.
           CL_SubsetSum_Solver M q0 enc âˆ§
           polytime_CL_machine M enc))"


section â€¹11.  LR-read-all-solvers hypothesisâ€º

text â€¹
This is the single modelling assumption.

For a fixed encoding enc0:

      LR_read_all_solvers_hypothesis enc0

means:

  (1) If SUBSETâ€“SUM âˆˆ P, a polynomial-time CL solver exists, and
  (2) Every CL solver satisfies LR-read, i.e. belongs to â€¹LR_Read_TMâ€º.

NP-membership is not assumed; it is proved separately.
â€º

definition LR_read_all_solvers_hypothesis ::
  "(int list â‡’ int â‡’ string) â‡’ bool" where
  "LR_read_all_solvers_hypothesis enc0 âŸ·
     P_impl_CL_SubsetSum_Solver enc0 âˆ§
     (âˆ€M q0 enc.
        CL_SubsetSum_Solver M q0 enc âŸ¶
          (âˆƒseenL seenR. LR_Read_TM M q0 enc seenL seenR))"


section â€¹12.  Core Conditional Theoremâ€º

text â€¹
This theorem expresses the logical core:

    LR assumptions  +  SUBSETâ€“SUM âˆˆ NP   â‡’   P â‰  NP.

Proof sketch:

    Assume P = NP.
    Then SUBSETâ€“SUM âˆˆ P.
    So a polynomial-time CL solver M exists.
    LR-read applies to M, giving a âˆš(2^n) lower bound.
    Contradiction with the polynomial-time upper bound.
â€º

lemma P_neq_NP_if_LR_read_all_solvers_hypothesis:
  fixes enc0 :: "int list â‡’ int â‡’ string"
  assumes H:       "LR_read_all_solvers_hypothesis enc0"
  assumes NP_enc0: "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  shows "Â¬ P_eq_NP"
proof -
  from H have
    bridge_P: "P_impl_CL_SubsetSum_Solver enc0" and
    all_LR:   "âˆ€M q0 enc.
                 CL_SubsetSum_Solver M q0 enc âŸ¶
                   (âˆƒseenL seenR. LR_Read_TM M q0 enc seenL seenR)"
    unfolding LR_read_all_solvers_hypothesis_def by blast+

  show "Â¬ P_eq_NP"
  proof
    assume eq: "P_eq_NP"

    have eq_PNP_inst:
      "(SUBSETSUM_lang enc0 âˆˆ ğ’«) = (SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«)"
      using eq unfolding P_eq_NP_def by simp

    have inP_SUBSETSUM: "SUBSETSUM_lang enc0 âˆˆ ğ’«"
      using NP_enc0 eq_PNP_inst by simp

    from bridge_P[unfolded P_impl_CL_SubsetSum_Solver_def] inP_SUBSETSUM
    obtain M q0 enc where
      solver: "CL_SubsetSum_Solver M q0 enc" and
      poly:   "polytime_CL_machine M enc"
      by blast

    from all_LR solver obtain seenL seenR where lr:
      "LR_Read_TM M q0 enc seenL seenR"
      by blast

    interpret LR: LR_Read_TM M q0 enc seenL seenR
      by (rule lr)

    from poly obtain c d where
      cpos: "c > 0" and
      bound_all: "âˆ€as s.
                    steps_CL M (enc as s)
                      â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
      unfolding polytime_CL_machine_def by blast

    have family_bound:
      "âˆƒ(c::real)>0. âˆƒd::nat.
         âˆ€as s. distinct_subset_sums as âŸ¶
           steps_CL M (enc as s)
             â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
      using cpos bound_all by blast

    from LR.no_polytime_CL_on_distinct_family family_bound
    show False by blast
  qed
qed


section â€¹13.  Final Packaged Theoremâ€º

text â€¹
This theorem gives the final wrapped statement:

      LR hypothesis + SUBSETâ€“SUM verifier â‡’ P â‰  NP.
â€º

theorem P_neq_NP_under_LR_model:
  fixes enc0 :: "int list â‡’ int â‡’ string"
  assumes LR: "LR_read_all_solvers_hypothesis enc0"
  assumes V:  "SS_Verifier_NP k G V p T fverify enc0 enc_cert"
  shows "Â¬ P_eq_NP"
proof -
  have NP_enc0: "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
    using SUBSETSUM_in_NP_global[OF V] .
  from P_neq_NP_if_LR_read_all_solvers_hypothesis[OF LR NP_enc0]
  show "Â¬ P_eq_NP" .
qed

end
