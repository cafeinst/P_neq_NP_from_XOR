theory SubsetSum_PneqNP
  imports SubsetSum_CookLevin
begin

text â€¹
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                             %
%      A CONDITIONAL PROOF THAT P â‰  NP FROM AN INFORMATIONâ€“FLOW PRINCIPLE     %
%                                                                             %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This theory completes the mechanised development of a conditional lower bound
for SUBSETâ€“SUM originating in

    C. A. Feinstein,
    â€œDialogue Concerning the Two Chief World Views,â€
    arXiv:1605.08639.

The analysis begins from a simple informational observation:

      To decide whether two integers L and R are equal,
      a solver must obtain some information about L
      and some information about R.

This principle, taken at face value, concerns only a *single pair* of integers.
It says nothing about candidate families, splits, or search spaces.  Its force in
the SUBSETâ€“SUM setting comes from the fact that, for any split position k, the
canonical decomposition eâ‚–(as,s) expresses the verification equation in terms of
two collections of *possible integers*:

      LHS(eâ‚– as s)      (size 2^k),
      RHS(eâ‚– as s)      (size 2^(n âˆ’ k)).

Each element of these sets is a distinct integer that L or R could take.  Thus, 
when viewed through the original principle, the solver is confronted not with one 
possible L and one possible R, but with 2^k possible Ls and 2^(n âˆ’ k) possible Rs.

It follows immediately that the solver must obtain *at least one unit of
information about each candidate integer*.  Otherwise, some L-candidate and some
R-candidate would remain indistinguishable, and the solver could not validly
conclude that none of these pairs satisfy L = R.

The challenge is to express this per-candidate informational requirement inside
the Cookâ€“Levin Turing-machine model.  In this setting the machine may reorder,
copy, or compress its input in ways that an adversary cannot track or restrict.
Because of this freedom, the standard adversary technique â€” which works in
decision-tree or query models â€” cannot enforce the per-candidate requirement:
once the entire input is visible, the adversary cannot prevent the machine from
computing derived representations that bypass the intended structure.

For this reason, the theory introduces LR-read as an explicit modelling
assumption.  LR-read formalises the idea that, for some split k, the machineâ€™s
observable behaviour distinguishes **exactly** the canonical L- and R-candidate
integers produced by eâ‚–(as,s).  It is not an additional assumption, but the 
direct formal realisation of the informational requirement stated above, 
expressed in the language of Cookâ€“Levin Turing machines.

Under LR-read, the mechanised development imports the abstract decision-tree
lower bound and shows that every solver must take at least

      2 Â· sqrt(2^n)

steps on distinct-subset-sum instances of length n.  Since âˆš(2^n) dominates all
polynomials, we obtain the conditional implication:

      If every polynomial-time solver for SUBSETâ€“SUM satisfies LR-read,
      then P â‰  NP.

All mathematical components other than LR-read â€” including the decision-tree
argument, Cookâ€“Levin machine semantics, and the NP verifier for SUBSETâ€“SUM â€” are
fully formalised and machine-checked in Isabelle/HOL.  LR-read is the sole
unproved assumption linking the original information-flow observation to the
behaviour of concrete Turing-machine solvers.

Acknowledgement:
The author received assistance from AI systems (ChatGPT by OpenAI and Claude by 
Anthropic) in drafting and polishing explanatory text and in iteratively refining 
Isabelle/HOL proof scripts.  All formal results and final proofs are the 
responsibility of the author.
â€º


section â€¹1.  Why SUBSETâ€“SUM?â€º

text â€¹
SUBSETâ€“SUM provides a setting in which the informational structure of a simple
equality test becomes explicit.  For an input list â€¹asâ€º of length â€¹nâ€º, each
0/1-vector â€¹xsâ€º defines a distinct integer

      âˆ‘áµ¢ as!i * xs!i.

On distinct-subset-sum instances these values are all different, so every xs
represents a different feasible outcome of the verification equation.

For any split position k, the canonical decomposition eâ‚–(as,s) separates these
possibilities into two collections of integers:

      LHS(eâ‚– as s)      of size 2^k,
      RHS(eâ‚– as s)      of size 2^(n âˆ’ k),

arising respectively from prefix-choices and suffix-choices of the unknown xs.
These sets enumerate all integers that the left- and right-hand sides could
possibly take at that split.

The informational principle stated in the introduction therefore applies
simultaneously to many possible L and many possible R: to rule out the existence
of a matching pair, the solver must distinguish the corresponding integer values
one by one.  This per-candidate requirement is the starting point for the
lower-bound analysis.
â€º


section â€¹2.  The Decision-Tree Lower Boundâ€º

text â€¹
The theory â€¹SubsetSum_DecisionTreeâ€º formalises the per-candidate informational
requirement in an abstract â€œreaderâ€ model.  Two axioms govern the model:

  â€¢ coverage â€” for each distinct-subset-sum instance, there exists a split k
      at which the solver distinguishes exactly the canonical candidate sets
      LHS(eâ‚–) and RHS(eâ‚–);

  â€¢ cost â€” distinguishing each candidate costs at least one unit of work.

From these axioms, the decision-tree argument derives the inequality

      steps(as, s)  â‰¥  2^k + 2^(n âˆ’ k),

and hence the tight lower bound

      steps(as, s)  â‰¥  2 Â· sqrt(2^n).

This bound is independent of Turing machines, encodings, or internal state.  
It isolates the combinatorial consequence of the informational principle:  
if a solver must handle each candidate integer individually, then it must incur
at least âˆš(2^n) work on some split.

The decision-tree theory â€¹SubsetSum_DecisionTreeâ€º already contains the
abstract lower-bound result â€¹SubsetSum_To_Polytimeâ€º.  That theorem states
that any solver satisfying the LRâ€“reader axioms of
â€¹SubsetSum_Lemma1â€º cannot run in polynomial time on all
distinct-subset-sum instances.

In the present theory we do not reprove this result.  Instead, we
combine it with the Cookâ€“Levin instantiation developed in
â€¹SubsetSum_CookLevinâ€º and a single modelling assumption:
that every polynomial-time SUBSETâ€“SUM solver satisfies the LRâ€“read
information principle.
â€º


section â€¹3.  From Decision Trees to Cookâ€“Levin Turing Machinesâ€º

text â€¹
A Cookâ€“Levin Turing machine does not reveal its information flow directly.  It
sees the entire input from the start and may internally rearrange, copy, or
compress it.  Thus the decision-tree axioms cannot be transferred automatically.

The locale â€¹LR_Read_TMâ€º provides the bridge.  For each instance it defines
observable sets

      seenL_TM as s k    and    seenR_TM as s k,

which record which canonical L- and R-candidates the machine's behaviour
effectively distinguishes.  The LR-read property asserts that for some split k
these observable sets match the canonical sets:

      seenL_TM as s k = LHS(eâ‚– as s),
      seenR_TM as s k = RHS(eâ‚– as s).

Together with a cost condition mirroring the decision-tree model, LR-read
instantiates the abstract lower-bound theorem with the concrete time measure
â€¹steps_TMâ€º of the Turing machine.
â€º


section â€¹4.  Why LR-read Is Assumedâ€º

text â€¹
The LR-read property is not proved in this development; it is introduced as a
modelling assumption.  This reflects a structural limitation of adversary
arguments in the unrestricted Turing-machine model.

In a decision tree, the solver learns information only by querying individual
positions, so an adversary can ensure that it obtains a separate unit of
information for each candidate.  A Turing machine, however, begins with full
visibility of its input and may internally transform it in ways the adversary
cannot monitor.  Nothing prevents the machine from computing derived summaries
that bypass the canonical prefix/suffix structure implicit in eâ‚–(as,s).

For this reason, one cannot expect the per-candidate requirement to follow from
standard adversary reasoning for Turing machines.  LR-read is therefore stated
explicitly to capture, within the Cookâ€“Levin model, the same informational
structure that drives the decision-tree lower bound.

Once LR-read is assumed, the abstract combinatorial lower bound applies
verbatim, yielding the âˆš(2^n) time requirement for any such solver.
â€º

section â€¹Information principle and canonical presentationsâ€º

text â€¹
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â–  Equality of two independent values
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  The underlying information principle used in our lower bound can be stated
  in very simple terms.

  Consider two independent integer values â€¹Lâ€º and â€¹Râ€º drawn from fixed sets
  â€¹Lvalsâ€º and â€¹Rvalsâ€º.  A procedure that decides, for every pair â€¹(L,R)â€º in
  â€¹Lvals Ã— Rvalsâ€º, whether the equality

        L = R

  holds must, in the worst case, obtain information from both components.
  Intuitively, there are inputs on which it has to distinguish between the
  different possibilities for â€¹Lâ€º, and likewise for â€¹Râ€º, in order to decide
  whether some equality is possible.

  In the theory â€¹SubsetSum_DecisionTreeâ€º this informal idea is captured by
  the small locale â€¹LR_Eq_Info_Principleâ€º.  That locale does *not* talk
  about subset sums or Turing machines; it merely packages the idea that a
  correct equality-decider for independent ranges â€¹Lvalsâ€º and â€¹Rvalsâ€º must,
  in the worst case, be able to separate each canonical value on the left
  and on the right.
â€º

text â€¹
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â–  Canonical LHS/RHS versus arbitrary presentations
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  For SUBSETâ€“SUM there are many ways to write an equivalent â€œverification
  equationâ€ for the same problem instance.  Starting from

        âˆ‘ i<n. as ! i * xs ! i = s,

  one can apply arbitrary algebraic manipulations or injective
  reparametrisations to obtain new presentations that have the same
  {0,1}-solutions but very different algebraic structure.  Some of these
  non-canonical equations may admit algorithmic shortcuts: for example,
  a reparametrisation could expose a common factor, or compress many
  equality constraints into a single arithmetical test.  Such shortcuts
  potentially reduce the *number of distinct values that need to be
  distinguished*.

  The abstract lower bound developed in â€¹SubsetSum_DecisionTreeâ€º therefore
  fixes a single, very structured family of presentations, indexed by a
  split position â€¹kâ€º:

      eâ‚– as s k xs = (L, R),

  where the left component â€¹Lâ€º is the weighted sum over the first â€¹kâ€º bits
  of â€¹xsâ€º and the right component â€¹Râ€º is the residual sum over the remaining
  bits.  For instances with distinct subset sums we proved that the
  associated value sets

      LHS (eâ‚– as s k) n,   RHS (eâ‚– as s k) n

  have maximal cardinalities

      card (LHS (eâ‚– as s k) n) = 2^k,
      card (RHS (eâ‚– as s k) n) = 2^(n âˆ’ k),

  and, crucially, that they arise from *independent* 0/1 choices in the left
  and right halves of the solution vector.  Every choice of left bits can
  be combined with every choice of right bits; there are no hidden algebraic
  dependencies between the two ranges.

  This canonical family plays the role of the â€œworst caseâ€ for our
  information principle: it realises the full product space of 2^k left
  values and 2^(nâˆ’k) right values, with no degeneracies.
â€º

text â€¹
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  â–  Why the lower bound only uses canonical presentations
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  One might ask why the lower bound is proved only for the canonical
  presentations â€¹eâ‚– as sâ€º rather than for *all* algebraically equivalent
  equations.  There are two reasons.

  â€¢ First, the goal of the lower bound is to exhibit a family of instances
    and presentations on which any solver that satisfies the LRâ€“equality
    information principle must perform Î©(âˆš(2â¿)) work.  For this purpose we
    do not need to analyse every clever reparametrisation of the subset-sum
    equation; it suffices to fix one natural family of equations whose
    left/right value sets are provably as large and as independent as
    possible.  The canonical splits â€¹eâ‚– as sâ€º meet exactly this need.

  â€¢ Second, allowing arbitrary non-canonical presentations would blur the
    boundary between the *information model* and the *algebraic ingenuity*
    of particular algorithms.  A solver might derive a non-canonical
    equation in which many of the 2â¿ formal possibilities collapse to a
    much smaller number of distinct values that need to be told apart.
    Such algebraic shortcuts are genuine algorithmic improvements, but they
    are outside the scope of the abstract reader model that
    â€¹SubsetSum_Lemma1â€º formalises.  The reader model is designed to capture
    the cost of distinguishing canonical LHS/RHS values arising directly
    from the underlying 0/1 choices, not the cost of arbitrary algebraic
    transformations of the equation.

  In short: the canonical presentations are chosen precisely because they
  expose the â€œpureâ€ combinatorial difficulty of separating all 2^k left
  values and 2^(nâˆ’k) right values coming from independent input sets.  Any
  solver that satisfies the LRâ€“equality principle on this canonical family
  must pay at least âˆš(2â¿) steps on some instances.  Non-canonical equations
  may or may not admit additional shortcuts, but those lie beyond the
  abstract cost model studied here.
â€º


section â€¹5.  Structure of the Developmentâ€º

text â€¹
The full conditional lower-bound argument is organised across three theories,
each addressing a distinct level of abstraction.

  â€¢ â€¹SubsetSum_DecisionTreeâ€º  
      Formalises the combinatorial core of the argument.  
      Under two axioms â€” coverage of canonical L/R candidates and
      a per-candidate cost condition â€” it proves the abstract bound

            steps(as, s)  â‰¥  2 Â· sqrt(2^n).

      This theory contains no reference to Turing machines or encodings.

  â€¢ â€¹SubsetSum_CookLevinâ€º  
      Connects the abstract model to the Cookâ€“Levin machine semantics.
      For a solver â€¹Mâ€º and encoding â€¹encâ€º, it defines concrete time and
      distinguishability measures (â€¹steps_TMâ€º and â€¹seenL_TMâ€º/â€¹seenR_TMâ€º).
      The locale â€¹LR_Read_TMâ€º states the assumptions that instantiate
      the abstract axioms with these concrete notions, thereby transporting
      the âˆš(2^n) lower bound to Cookâ€“Levin Turing machines.

  â€¢ â€¹SubsetSum_PneqNPâ€º (the present theory)  
      Places the lower bound in a complexity-theoretic context.
      A separate, fully formalised verifier shows that SUBSETâ€“SUM lies in
      â€¹ğ’©ğ’«â€º for any reasonable encoding.  
      Combining NP-membership with the conditional lower bound obtained
      under LR-read yields the main implication:

            If every polynomial-time solver satisfies LR-read,
            then P â‰  NP.

This layering isolates the mathematical content of the lower bound, the
operational content of the Turing-machine model, and the logical structure of
the conditional separation.  Only LR-read is assumed; all other components are
fully mechanised in Isabelle/HOL.
â€º

section â€¹A global LR-read axiom for SUBSET-SUM solversâ€º

text â€¹
  We now postulate an information-flow axiom at the Cookâ€“Levin level:

    Any Cookâ€“Levin machine that correctly decides SUBSET-SUM
    in polynomial time (with respect to â€¹length asâ€º) admits an
    LR-read presentation in the sense of â€¹LR_Read_TMâ€º.
â€º

locale LR_Read_Axiom =
  fixes M   :: machine
    and q0  :: nat
    and enc :: "int list â‡’ int â‡’ bool list"
  assumes LR_Read_for_all_poly_solvers:
    "âŸ¦ CL_SubsetSum_Solver M q0 enc;
       polytime_CL_machine M enc âŸ§
     âŸ¹ âˆƒsteps_TM seenL_TM seenR_TM.
           LR_Read_TM M q0 enc steps_TM seenL_TM seenR_TM"
begin

text â€¹
  Under this axiom, there cannot exist a polynomial-time
  Cookâ€“Levin SUBSET-SUM solver: any such solver would give
  rise to an LR-read instance of â€¹LR_Read_TMâ€º, contradicting
  â€¹no_polytime_CL_on_distinct_familyâ€º.
â€º

lemma no_polytime_CL_SubsetSum_solver:
  assumes solver: "CL_SubsetSum_Solver M q0 enc"
      and poly:   "polytime_CL_machine M enc"
  shows False
proof -
  (* 1. From the axiom, get LR_Read_TM for this solver *)
  from LR_Read_for_all_poly_solvers[OF solver poly]
  obtain steps_TM seenL_TM seenR_TM
    where LR: "LR_Read_TM M q0 enc steps_TM seenL_TM seenR_TM"
    by blast

  (* 2. Work *inside* that LR_Read_TM instance *)
  interpret LR_Read_TM M q0 enc steps_TM seenL_TM seenR_TM
    by (rule LR)

  (* 3. Unpack the polynomial-time assumption for M, enc *)
  from poly obtain c d where
    cpos: "c > 0" and
    bound_all:
      "âˆ€as s. steps_CL M (enc as s)
                â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
    unfolding polytime_CL_machine_def
    by blast

  (* 4. Restrict that bound to distinct-subset-sum instances *)
  have bound_restricted:
    "âˆ€as s. distinct_subset_sums as âŸ¶
             steps_CL M (enc as s)
               â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
    using bound_all by blast

  (* 5. Package it into the existential form that contradicts
        no_polytime_CL_on_distinct_family *)
  have ex_poly_on_distinct:
    "âˆƒ(c::real)>0. âˆƒ(d::nat).
       âˆ€as s. distinct_subset_sums as âŸ¶
         steps_CL M (enc as s)
           â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
    by (intro exI[of _ c] exI[of _ d] conjI cpos bound_restricted)

  (* 6. Contradiction with the LR_Read_TM-level impossibility theorem *)
  from no_polytime_CL_on_distinct_family ex_poly_on_distinct
  show False
    by blast
qed

text â€¹
  A convenient corollary: assuming â€¹LR_Read_Axiomâ€º, there is
  no polynomial-time Cookâ€“Levin machine that solves SUBSET-SUM.
â€º

corollary no_polytime_SubsetSum:
  assumes solver: "CL_SubsetSum_Solver M q0 enc"
  shows "Â¬ polytime_CL_machine M enc"
proof
  assume poly: "polytime_CL_machine M enc"
  from no_polytime_CL_SubsetSum_solver[OF solver poly]
  show False .
qed

end  (* locale LR_Read_Axiom *)


section â€¹6.  SUBSETâ€“SUM is in NP (formalised)â€º

text â€¹
  The technical work showing that SUBSETâ€“SUM belongs to â€¹ğ’©ğ’«â€º has already been
  carried out in â€¹SubsetSum_CookLevinâ€º.  There we introduced the locale
  â€¹SS_Verifier_NPâ€º, which packages an arbitrary NP-style verifier for
  SUBSETâ€“SUM (instance and certificate encodings, a polynomial-time verifier
  machine, and soundness/completeness assumptions), and proved the lemma

      SUBSETSUM_in_NP_from_verifier :
        SS_Verifier_NP k G V p T fverify enc0 enc_cert
        âŸ¹ SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«.

  In the present theory we simply reuse that result under a slightly more
  convenient name:
â€º

lemma SUBSETSUM_in_NP_global:
  assumes "SS_Verifier_NP k G V p T fverify enc0 enc_cert"
  shows "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  using SUBSETSUM_in_NP_from_verifier[OF assms] .

section â€¹7.  Definition of P = NPâ€º

definition P_eq_NP :: bool where
  "P_eq_NP âŸ· (âˆ€L::language. (L âˆˆ ğ’«) = (L âˆˆ ğ’©ğ’«))"

section â€¹8.  Bridging P to a concrete CL solverâ€º

text â€¹
If SUBSETâ€“SUM âˆˆ P, then some Cookâ€“Levin machine solves it in polynomial time.

This step passes from language complexity to concrete machine semantics.
The solverâ€™s encoding need not match the verifierâ€™s encoding; only the language
matters.
â€º

definition P_impl_CL_SubsetSum_Solver ::
  "(int list â‡’ int â‡’ string) â‡’ bool" where
  "P_impl_CL_SubsetSum_Solver enc0 âŸ·
     (SUBSETSUM_lang enc0 âˆˆ ğ’« âŸ¶
        (âˆƒM q0 enc.
           CL_SubsetSum_Solver M q0 enc âˆ§
           polytime_CL_machine M enc))"

definition IP_TM :: "machine â‡’ nat â‡’ (int list â‡’ int â‡’ bool list) â‡’ bool" where
  "IP_TM M q0 enc âŸ·
     (âˆƒsteps_TM seenL_TM seenR_TM.
        LR_Read_TM M q0 enc steps_TM seenL_TM seenR_TM)"


section â€¹9.  IP-read-all-solvers hypothesisâ€º

text â€¹
This is the single modelling assumption.

For a fixed encoding enc0:

      LR_read_all_solvers_hypothesis enc0

means:

  (1) If SUBSETâ€“SUM âˆˆ P, a polynomial-time CL solver exists, and
  (2) Every CL solver satisfies LR-read, i.e. belongs to â€¹LR_Read_TMâ€º.

NP-membership is not assumed; it is proved separately.
â€º

definition IP_all_poly_solvers_hypothesis ::
  "(int list â‡’ int â‡’ string) â‡’ bool" where
  "IP_all_poly_solvers_hypothesis enc0 âŸ·
     P_impl_CL_SubsetSum_Solver enc0 âˆ§
     (âˆ€M q0 enc.
        CL_SubsetSum_Solver M q0 enc âŸ¶ polytime_CL_machine M enc âŸ¶ IP_TM M q0 enc)"

section â€¹10.  Core Conditional Theoremâ€º

text â€¹
This theorem expresses the logical core:

    LR assumptions  +  SUBSETâ€“SUM âˆˆ NP   â‡’   P â‰  NP.

Proof sketch:

    Assume P = NP.
    Then SUBSETâ€“SUM âˆˆ P.
    So a polynomial-time CL solver M exists.
    LR-read applies to M, giving a âˆš(2^n) lower bound.
    Contradiction with the polynomial-time upper bound.
â€º

lemma P_neq_NP_if_IP_all_poly_solvers_hypothesis:
  fixes enc0 :: "int list â‡’ int â‡’ string"
  assumes H:       "IP_all_poly_solvers_hypothesis enc0"
  assumes NP_enc0: "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  shows "Â¬ P_eq_NP"
proof -
  from H have
    bridge_P: "P_impl_CL_SubsetSum_Solver enc0" and
    all_IP:   "âˆ€M q0 enc.
                CL_SubsetSum_Solver M q0 enc âŸ¶ polytime_CL_machine M enc âŸ¶ IP_TM M q0 enc"
    unfolding IP_all_poly_solvers_hypothesis_def by blast+

  show "Â¬ P_eq_NP"
  proof
    assume eq: "P_eq_NP"

    have eq_PNP_inst:
      "(SUBSETSUM_lang enc0 âˆˆ ğ’«) = (SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«)"
      using eq unfolding P_eq_NP_def by simp

    have inP_SUBSETSUM: "SUBSETSUM_lang enc0 âˆˆ ğ’«"
      using NP_enc0 eq_PNP_inst by simp

    from bridge_P[unfolded P_impl_CL_SubsetSum_Solver_def] inP_SUBSETSUM
    obtain M q0 enc where
      solver: "CL_SubsetSum_Solver M q0 enc" and
      poly:   "polytime_CL_machine M enc"
      by blast

    from all_IP solver poly have "IP_TM M q0 enc" by blast
    then obtain steps_TM seenL_TM seenR_TM where lr:
      "LR_Read_TM M q0 enc steps_TM seenL_TM seenR_TM"
      unfolding IP_TM_def by blast

    interpret LR: LR_Read_TM M q0 enc steps_TM seenL_TM seenR_TM
      by (rule lr)

    from poly obtain c d where
      cpos: "c > 0" and
      bound_all: "âˆ€as s.
                    steps_CL M (enc as s)
                      â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
      unfolding polytime_CL_machine_def by blast

    have family_bound:
      "âˆƒ(c::real)>0. âˆƒd::nat.
         âˆ€as s. distinct_subset_sums as âŸ¶
           steps_CL M (enc as s)
             â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
      using cpos bound_all by blast

    from LR.no_polytime_CL_on_distinct_family family_bound
    show False by blast
  qed
qed

section â€¹11.  Final Packaged Theoremâ€º

text â€¹
This theorem gives the final wrapped statement:

      LR hypothesis + SUBSETâ€“SUM verifier â‡’ P â‰  NP.
â€º

theorem P_neq_NP_under_IP:
  fixes enc0 :: "int list â‡’ int â‡’ string"
  assumes IP: "IP_all_poly_solvers_hypothesis enc0"
  assumes V:  "SS_Verifier_NP k G V p T fverify enc0 enc_cert"
  shows "Â¬ P_eq_NP"
proof -
  have NP_enc0: "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
    using SUBSETSUM_in_NP_global[OF V] .
  show "Â¬ P_eq_NP"
    using P_neq_NP_if_IP_all_poly_solvers_hypothesis[OF IP NP_enc0] .
qed

end
