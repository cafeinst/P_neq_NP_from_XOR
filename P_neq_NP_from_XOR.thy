theory SubsetSum_PneqNP
  imports SubsetSum_CookLevin
begin

text â€¹
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                            %
%        A CONDITIONAL PROOF THAT P != NP FROM AN INFORMATION-FLOW PRINCIPLE %
%                                                                            %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

This theory completes a fully mechanised formalisation of the lower-bound
argument for SUBSETâ€“SUM that originates in

      C. A. Feinstein,
      â€œDialogue Concerning the Two Chief World Views,â€
      arXiv:1605.08639.

The original insight is the informal information-flow principle:

      To decide whether two quantities L and R are equal,
      a solver must read at least one bit encoding L
      and at least one bit encoding R.

In this theory, that slogan serves only as intuitive motivation.  
The actual lower-bound argument is carried out entirely inside Isabelle/HOL
and depends on a stronger, explicitly stated modelling assumption called
LR-read.  LR-read captures, in precise mathematical form, the requirement that
a solver for SUBSETâ€“SUM must extract enough information from the parts of the
input that influence L and from the parts that influence R, in order to
distinguish all canonical prefix and suffix contributions.

Under this assumption, the formalisation proves that any Turing machine
solving SUBSETâ€“SUM must take at least âˆš(2^n) steps on inputs of length n.
Since âˆš(2^n) grows faster than any polynomial, this yields the conditional
statement:

      If every polynomial-time solver for SUBSETâ€“SUM satisfies LR-read,
      then P != NP.

All mathematics behind the lower bound â€” decision-tree adversary reasoning,
the Cookâ€“Levin Turing-machine semantics, and the NP verifier for SUBSETâ€“SUM â€”
is fully mechanised.  LR-read itself is the only non-mechanised assumption,
made explicit and never used implicitly.

AI systems (ChatGPT and Claude) assisted in structuring the presentation,
improving exposition, and refining comments, while all formal proofs are
verified by Isabelle/HOL.
â€º


section â€¹1.  Why SUBSETâ€“SUM?â€º

text â€¹
The SUBSETâ€“SUM problem asks whether, for integers

    as = [aâ‚€, â€¦, aâ‚™â‚‹â‚]  and  target s,

there exists a 0/1-vector xs such that

      âˆ‘áµ¢ as!i * xs!i = s.

Some inputs â€” such as as = [1,2,4,â€¦,2^(nâˆ’1)] â€” have the property that *all*
2â¿ subset sums are distinct.  More generally, any list as with this property is
called a distinct-subset-sum instance.  These instances form a large family and
serve as the canonical adversarial cases for the lower bound.  No special
algorithmic hardness is ascribed to the powers-of-two examples beyond their
distinct-subset-sum structure.
â€º


section â€¹2.  The Decision-Tree Lower Boundâ€º

text â€¹
The theory â€¹SubsetSum_DecisionTreeâ€º defines an abstract â€œreaderâ€ model and
establishes the lower bound

      steps(as, s)  â‰¥  2 * sqrt(2^n)

for all distinct-subset-sum inputs as of length n.

The model is an adversarial process:

  â€¢ the solver reads bits of the true input (as, s),
  â€¢ the adversary tracks all completions xs âˆˆ {0,1}â¿ still compatible with
    the solverâ€™s observations,
  â€¢ for each split k, the canonical equation eâ‚–(as,s) separates the sum:

        LHS depends on xs[0..kâˆ’1]
        RHS depends on xs[k..nâˆ’1].

As xs varies, LHS takes exactly 2^k values and RHS takes exactly 2^(nâˆ’k)
values.  The abstract axioms of â€¹SubsetSum_Lemma1â€º require:

  (A1) the solverâ€™s information flow matches these canonical LHS/RHS families,
  (A2) each distinguishable value costs â‰¥ 1 step.

Thus the solverâ€™s cost is at least

      2^k + 2^(nâˆ’k),

minimised at 2 * sqrt(2^n).
â€º


section â€¹3.  From Decision Trees to Cookâ€“Levin Turing Machinesâ€º

text â€¹
A Cookâ€“Levin Turing machine is far more flexible than a decision tree: it may
reorder, copy, compress, or interleave parts of its input tape.  Therefore,
the decision-tree lower bound does not automatically carry over.

To bridge this gap, the theory â€¹SubsetSum_CookLevinâ€º introduces the locale
â€¹LR_Read_TMâ€º.  Its purpose is to package, in a precise axiomatic form, the
left/right information structure that underlies the intuitive principle stated
at the beginning of this theory:

      â€œTo decide whether two quantities L and R are equal,
       a solver must read at least one bit encoding L
       and at least one bit encoding R.â€

For SUBSETâ€“SUM, these quantities L and R arise from the canonical split of the
verification equation at position k:

      L = âˆ‘áµ¢â‚áµ¢<â‚–â‚ as!i * xs!i          (prefix contribution)
      R = s âˆ’ âˆ‘áµ¢â‚áµ¢â‰¥â‚–â‚ as!i * xs!i      (suffix contribution).

Varying the prefix bits xs[0..kâˆ’1] yields exactly 2^k different possible
L-values, while varying the suffix bits xs[k..nâˆ’1] yields 2^(nâˆ’k) different
possible R-values.  These canonical sets are written:

      LHS(eâ‚– as s)    and    RHS(eâ‚– as s).

Even when no L equals any R, the solver must still discriminate among all
these possibilities.  Since it does not know the choice vector xs, each
candidate L-value is one that could arise from some prefix xs[0..kâˆ’1], and
each candidate R-value is one that could arise from some suffix xs[k..nâˆ’1].
To decide whether any equality L = R can occur, the solver must obtain enough
information from the encoded instance to rule out (or confirm) each of these
candidates.  Consequently, it must gather enough information to distinguish
all 2^k prefix-derived L-values and all 2^(nâˆ’k) suffix-derived R-values.

To express this notion inside the Cookâ€“Levin machine model, we examine how the
machineâ€™s behaviour changes when we modify the input in ways that alter only
prefix-relevant information (affecting L but not R) or only suffix-relevant
information (affecting R but not L).  This leads to the definitions:

  â€¢ â€¹seenL_TM as s kâ€º = the set of canonical L-values that the machineâ€™s
    behaviour can distinguish at split k;

  â€¢ â€¹seenR_TM as s kâ€º = the analogous set of distinguishable R-values.

These sets represent what the machine has effectively learned about L and R
from the bits it has read.

-------------------------------------------------------------------------------
â–   LR-read: matching the canonical left/right family
-------------------------------------------------------------------------------

The LR-read hypothesis asserts that, for every distinct-subset-sum instance
(as,s), there exists some split k such that

      seenL_TM as s k = LHS(eâ‚– as s)
      seenR_TM as s k = RHS(eâ‚– as s).

Thus the machineâ€™s observable behaviour must distinguish precisely all
canonical L-values and all canonical R-values.  It neither misses any nor
creates non-canonical distinctions.  This expresses, in a rigorous form, the
idea that a solver for L = R must obtain enough input information to determine
the status of every left candidate and every right candidate.

-------------------------------------------------------------------------------
â–   The cost principle
-------------------------------------------------------------------------------

The second LR-read axiom states:

      steps_TM as s â‰¥ |seenL_TM as s k| + |seenR_TM as s k|.

Each distinguishable canonical value incurs at least one unit of work.

Combining this with the equalities above gives:

      |seenL_TM as s k| = 2^k,
      |seenR_TM as s k| = 2^(nâˆ’k),

and hence

      steps_TM as s â‰¥ 2^k + 2^(nâˆ’k) â‰¥ 2 * sqrt(2^n).

This matches exactly the lower bound proved abstractly in
â€¹SubsetSum_Lemma1â€º.  LR-read therefore provides the bridge that lifts the
decision-tree lower bound to Cookâ€“Levin Turing machines.
â€º


section â€¹4.  Why LR-read is Assumedâ€º

text â€¹
The LR-read property is a modeling assumption: we do not attempt to prove that
every Turing-machine solver for SUBSETâ€“SUM satisfies it.  This section explains
three points:

  â€¢ why LR-read is a natural strengthening of the intuitive idea that to decide
    L = R one must obtain information about both L and R;

  â€¢ why LR-read is not expected to be derivable from general principles of
    computability or adversary arguments;

  â€¢ how this relates to Gregory Chaitinâ€™s perspective on mathematical axioms and
    unprovability (cf. â€œThoughts on the Riemann Hypothesisâ€, arXiv:math/0306042).

-------------------------------------------------------------------------------
â–   Why LR-read is a natural strengthening of the intuitive principle
-------------------------------------------------------------------------------

In SUBSETâ€“SUM, the expressions

      L = âˆ‘áµ¢â‚áµ¢<â‚–â‚ as!i * xs!i     and     R = s âˆ’ âˆ‘áµ¢â‚áµ¢â‰¥â‚–â‚ as!i * xs!i

are not fixed numbers.  Because the solver never sees the choice vector xs, each
of L and R ranges over exponentially many values as xs varies:

      LHS(eâ‚– as s) contains 2^k values,
      RHS(eâ‚– as s) contains 2^(nâˆ’k) values.

To decide whether L = R, the solver must rule out many of these possibilities on
each side.  LR-read formalises this requirement by postulating that, for some
split k, the solverâ€™s observable behaviour distinguishes *exactly* the canonical
families LHS(eâ‚– as s) and RHS(eâ‚– as s).  This aligns its information flow with
the combinatorial structure that drives the âˆš(2^n) lower bound.

-------------------------------------------------------------------------------
â–   Why LR-read is not provable by adversary or diagonal arguments
-------------------------------------------------------------------------------

One might hope to *prove* LR-read using an adversary argument: if a solver never
obtains enough information to distinguish the canonical L- and R-values, the
adversary should be able to force incorrect behaviour.  However, in the
Turing-machine setting this strategy breaks down.

A Turing machine may transform its input in arbitrarily complex waysâ€”compress,
hash, fold, interleave, or encode it into new formsâ€”and it can base its
computation on such transformations rather than on cleanly separated â€œL-sectionsâ€
and â€œR-sectionsâ€ of the input.  Because these internal representations are not
visible to the adversary, an adversary cannot guarantee that hiding or altering
a specific set of input bits prevents the machine from inferring some combined
property of L and R.

This is closely related to a broader theme in computability theory: many
structural properties of Turing-machine behaviour cannot be forced by
adversarial indistinguishability arguments alone.  While classical Rice-style
results do not apply directly â€” LR-read is not a semantic property of a
language â€” they illustrate the same phenomenon: Turing machines can compute in
ways that are opaque to combinatorial reasoning imposed on their input formats.
Thus no current general method is capable of proving a principle as specific as
LR-read for *all* Turing-machine solvers.

For this reason, LR-read is treated as an explicit external axiom: a deliberately
strengthened information-flow requirement chosen to match the combinatorial
conditions of the decision-tree lower bound.

-------------------------------------------------------------------------------
â–   A Chaitin-style perspective on axioms and unprovability
-------------------------------------------------------------------------------

In his article â€œThoughts on the Riemann Hypothesisâ€ (arXiv:math/0306042),
Gregory Chaitin argues that even classical number theory contains natural
statements whose truth cannot be proven from the usual axioms.
His message is that some global structural factsâ€”especially those involving
Diophantine equations or deep analytic behaviourâ€”may require new axioms
because no finite formal system can encode all of the information needed to
derive them.

The LR-read principle plays an analogous role in this development.
It asserts a structural constraint on how SUBSETâ€“SUM solvers must extract
information from their inputs in order to decide whether a prefix-derived
L-value can ever equal a suffix-derived R-value. This constraint is mathematically 
natural once the combinatorics of canonically split equations is examined, 
butâ€”just as in Chaitinâ€™s examplesâ€”it cannot presently be derived from the 
bare Turing-machine semantics that Isabelle formalises.

Accordingly, LR-read is taken here as an explicit axiom describing the
information pattern that any solver must satisfy on the hard family of
instances. Once accepted, this single structural assumption unlocks the rest of the
formal argument: the âˆš(2^n) lower bound follows automatically from the
decision-tree theory, and the Cookâ€“Levin bridge lifts that bound to Turing
machines.

Thus, LR-read occupies the same philosophical position that Chaitin highlights:
a natural, high-level principle about the structure of a problemâ€”one that may
lie beyond what can be proven in the underlying formal system, but whose
adoption yields strong and otherwise unreachable consequences.
â€º


section â€¹5.  Logical Structureâ€º

text â€¹
The development is organised in three layers:

  (1) Lower-bound kernel â€” *proved*
      Theories â€¹SubsetSum_DecisionTreeâ€º and â€¹SubsetSum_Lemma1â€º prove a
      âˆš(2^n) lower bound under abstract L/R-information axioms.

  (2) Cookâ€“Levin bridge â€” *proved*
      The locale â€¹LR_Read_TMâ€º formalises how a Turing machine induces the
      distinguishability sets â€¹seenL_TMâ€º and â€¹seenR_TMâ€º required by the
      abstract lemma.

  (3) Modeling assumption â€” *not proved*
      Every solver for SUBSETâ€“SUM satisfies LR-read.

Together these yield the conditional implication:

      If SUBSETâ€“SUM âˆˆ P and all solvers satisfy LR-read,
      then P â‰  NP.
â€º


section â€¹6.  Relation to Feinstein (2016)â€º

text â€¹
Feinstein argued informally that verifying equality of two subset-sum
expressions requires exploring many combinations of prefix/suffix choices for
xs.  This development captures the combinatorial core of that reasoning via the
families LHS(eâ‚–) and RHS(eâ‚–), formalises the corresponding decision-tree lower
bound, and identifies LR-read as the structural assumption needed to transfer
the argument to Turing machines.

The lower bound itself and its transfer to TMs are fully mechanised in
Isabelle/HOL; LR-read is the unique external assumption.
â€º


section â€¹7.  Perspectiveâ€º

text â€¹
This theory does not prove P â‰  NP.  Instead, it decomposes the argument into

  â€¢ a fully formalised lower-bound mechanism, and
  â€¢ a single explicit modeling assumption (LR-read).

If LR-read were justified independently â€” for example, by an argument that every
solver must process the encoding of (as, s) in a leftâ€“right sensitive way â€”
then the formalisation here would yield P â‰  NP immediately.

Thus the contribution is twofold:
  (a) a verified lower-bound framework for SUBSETâ€“SUM, and
  (b) a precise identification of the sole hypothesis on which the conditional
      separation relies.
â€º


section â€¹8.  SUBSETâ€“SUM is in NP (formalised)â€º

text â€¹
The Cookâ€“Levin AFP library does not supply SUBSETâ€“SUM âˆˆ NP by default.
Instead we obtain it from a general verifier via SS_Verifier_NP.

A verifier provides:

  â€¢ encodings of instances and certificates,
  â€¢ a polynomial-time TM verifier V,
  â€¢ soundness and completeness.

From this we derive:

      SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«.
â€º

lemma SUBSETSUM_in_NP_global:
  assumes "SS_Verifier_NP k G V p T fverify enc0 enc_cert"
  shows "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  using SUBSETSUM_in_NP_from_verifier[OF assms] .


section â€¹9.  Definition of P = NPâ€º

definition P_eq_NP :: bool where
  "P_eq_NP âŸ· (âˆ€L::language. (L âˆˆ ğ’«) = (L âˆˆ ğ’©ğ’«))"


section â€¹10.  Bridging P to a concrete CL solverâ€º

text â€¹
If SUBSETâ€“SUM âˆˆ P, then some Cookâ€“Levin machine solves it in polynomial time.

This step passes from language complexity to concrete machine semantics.
The solverâ€™s encoding need not match the verifierâ€™s encoding; only the language
matters.
â€º

definition P_impl_CL_SubsetSum_Solver ::
  "(int list â‡’ int â‡’ string) â‡’ bool" where
  "P_impl_CL_SubsetSum_Solver enc0 âŸ·
     (SUBSETSUM_lang enc0 âˆˆ ğ’« âŸ¶
        (âˆƒM q0 enc.
           CL_SubsetSum_Solver M q0 enc âˆ§
           polytime_CL_machine M enc))"


section â€¹11.  LR-read-all-solvers hypothesisâ€º

text â€¹
This is the single modelling assumption.

For a fixed encoding enc0:

      LR_read_all_solvers_hypothesis enc0

means:

  (1) If SUBSETâ€“SUM âˆˆ P, a polynomial-time CL solver exists, and
  (2) Every CL solver satisfies LR-read, i.e. belongs to â€¹LR_Read_TMâ€º.

NP-membership is not assumed; it is proved separately.
â€º

definition LR_read_all_solvers_hypothesis ::
  "(int list â‡’ int â‡’ string) â‡’ bool" where
  "LR_read_all_solvers_hypothesis enc0 âŸ·
     P_impl_CL_SubsetSum_Solver enc0 âˆ§
     (âˆ€M q0 enc.
        CL_SubsetSum_Solver M q0 enc âŸ¶
          (âˆƒseenL seenR. LR_Read_TM M q0 enc seenL seenR))"


section â€¹12.  Core Conditional Theoremâ€º

text â€¹
This theorem expresses the logical core:

    LR assumptions  +  SUBSETâ€“SUM âˆˆ NP   â‡’   P â‰  NP.

Proof sketch:

    Assume P = NP.
    Then SUBSETâ€“SUM âˆˆ P.
    So a polynomial-time CL solver M exists.
    LR-read applies to M, giving a âˆš(2^n) lower bound.
    Contradiction with the polynomial-time upper bound.
â€º

lemma P_neq_NP_if_LR_read_all_solvers_hypothesis:
  fixes enc0 :: "int list â‡’ int â‡’ string"
  assumes H:       "LR_read_all_solvers_hypothesis enc0"
  assumes NP_enc0: "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
  shows "Â¬ P_eq_NP"
proof -
  from H have
    bridge_P: "P_impl_CL_SubsetSum_Solver enc0" and
    all_LR:   "âˆ€M q0 enc.
                 CL_SubsetSum_Solver M q0 enc âŸ¶
                   (âˆƒseenL seenR. LR_Read_TM M q0 enc seenL seenR)"
    unfolding LR_read_all_solvers_hypothesis_def by blast+

  show "Â¬ P_eq_NP"
  proof
    assume eq: "P_eq_NP"

    have eq_PNP_inst:
      "(SUBSETSUM_lang enc0 âˆˆ ğ’«) = (SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«)"
      using eq unfolding P_eq_NP_def by simp

    have inP_SUBSETSUM: "SUBSETSUM_lang enc0 âˆˆ ğ’«"
      using NP_enc0 eq_PNP_inst by simp

    from bridge_P[unfolded P_impl_CL_SubsetSum_Solver_def] inP_SUBSETSUM
    obtain M q0 enc where
      solver: "CL_SubsetSum_Solver M q0 enc" and
      poly:   "polytime_CL_machine M enc"
      by blast

    from all_LR solver obtain seenL seenR where lr:
      "LR_Read_TM M q0 enc seenL seenR"
      by blast

    interpret LR: LR_Read_TM M q0 enc seenL seenR
      by (rule lr)

    from poly obtain c d where
      cpos: "c > 0" and
      bound_all: "âˆ€as s.
                    steps_CL M (enc as s)
                      â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
      unfolding polytime_CL_machine_def by blast

    have family_bound:
      "âˆƒ(c::real)>0. âˆƒd::nat.
         âˆ€as s. distinct_subset_sums as âŸ¶
           steps_CL M (enc as s)
             â‰¤ nat (ceiling (c * (real (length as)) ^ d))"
      using cpos bound_all by blast

    from LR.no_polytime_CL_on_distinct_family family_bound
    show False by blast
  qed
qed


section â€¹13.  Final Packaged Theoremâ€º

text â€¹
This theorem gives the final wrapped statement:

      LR hypothesis + SUBSETâ€“SUM verifier â‡’ P â‰  NP.
â€º

theorem P_neq_NP_under_LR_model:
  fixes enc0 :: "int list â‡’ int â‡’ string"
  assumes LR: "LR_read_all_solvers_hypothesis enc0"
  assumes V:  "SS_Verifier_NP k G V p T fverify enc0 enc_cert"
  shows "Â¬ P_eq_NP"
proof -
  have NP_enc0: "SUBSETSUM_lang enc0 âˆˆ ğ’©ğ’«"
    using SUBSETSUM_in_NP_global[OF V] .
  from P_neq_NP_if_LR_read_all_solvers_hypothesis[OF LR NP_enc0]
  show "Â¬ P_eq_NP" .
qed

end
